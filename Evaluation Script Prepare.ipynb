{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41d9fa39-1bb8-441a-bee5-38540b8d6faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from data import TrainStation\n",
    "from motsynth import MOTSynth, MOTSynthBlackBG\n",
    "from log_utils import log_summary\n",
    "from utils import save_ckpt, load_ckpt, print_scalor\n",
    "from common import *\n",
    "import parse\n",
    "from utils import spatial_transform, visualize\n",
    "from tensorboardX import SummaryWriter\n",
    "from scalor import SCALOR\n",
    "from pycocotools import mask as coco_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c519f74-61d8-416f-bdf9-33e977f397f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8985370c-e91f-4a3d-874f-42827f487241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_coco_poly_to_mask(segmentations, height, width):\n",
    "    masks = []\n",
    "    for polygons in segmentations:\n",
    "        if isinstance(polygons['counts'], list):\n",
    "            rles = coco_mask.frPyObjects(polygons, height, width)\n",
    "        \n",
    "        else:\n",
    "            rles = [polygons]\n",
    "\n",
    "        mask = coco_mask.decode(rles)\n",
    "        if len(mask.shape) < 3:\n",
    "            mask = mask[..., None]\n",
    "        #mask = torch.as_tensor(mask, dtype=torch.uint8)\n",
    "        #mask = mask.any(dim=2)\n",
    "        masks.append(mask)\n",
    "    # if masks:\n",
    "    #     masks = torch.stack(masks, dim=0)\n",
    "    # else:\n",
    "    #     masks = torch.zeros((0, height, width), dtype=torch.uint8)\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cdc9ee2-2a2c-4fae-92fe-44e6ca8f3565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_IoU(pred, target):\n",
    "    '''\n",
    "    Calculates the Intersection over Union(Intersection over Union).\n",
    "    '''\n",
    "    intersection = np.logical_and(target, pred)\n",
    "    union = np.logical_or(target, pred)\n",
    "    iou_score = np.sum(intersection) / np.sum(union)\n",
    "\n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8310337d-b5b0-451f-bde5-c7411dbb41d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('predictions_toy.json') as f:\n",
    "#     preds = json.load(f)\n",
    "# video28_objects = [p for p in preds if p[\"video_id\"] == 28]\n",
    "# video28_objects_dict = {i:obj for i, obj in enumerate(video28_objects)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10ee2e8a-016d-4cb7-a9fc-a3d643889f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('predictions_model_perceptual_gan_v2_7x7_003.json') as f:\n",
    "    preds = json.load(f)\n",
    "    \n",
    "# with open('predictions_toy.json') as f:\n",
    "#     preds = json.load(f)\n",
    "annotation_indices = [28, 33, 42, 59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d04e29c-d64b-4b8d-bc9f-620607ddadbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92b91ea7-d714-4105-afd6-da75321ca047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8782"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2099eea-1e96-42cc-8f59-d15b24958f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-b3e3190e6bba>:7: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  iou_score = np.sum(intersection) / np.sum(union)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 done.\n",
      "33 done.\n",
      "42 done.\n",
      "59 done.\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.1\n",
    "import copy\n",
    "\n",
    "last_preds_list = []\n",
    "counter = 0\n",
    "for ann_idx in annotation_indices:\n",
    "    video_objects = [p for p in preds if p[\"video_id\"] == ann_idx]\n",
    "    video_objects_dict = {i:obj for i, obj in enumerate(video_objects)}\n",
    "    \n",
    "    for i in range(9, 350, 10):\n",
    "\n",
    "    #     candidate_objs = [(idx, obj) for (idx, obj) in enumerate(video_objects) if obj[\"segmentations\"][i] != None]\n",
    "        candidate_objs = [(idx, obj) for idx, obj in video_objects_dict.items() if obj[\"segmentations\"][i] != None]\n",
    "    #     objs_to_concetenate = [(idx, obj) for (idx, obj) in enumerate(video_objects) if obj[\"segmentations\"][i+1] != None]\n",
    "        objs_to_concetenate = [(idx, obj) for idx, obj in video_objects_dict.items() if obj[\"segmentations\"][i+1] != None]\n",
    "\n",
    "        keys_to_remove_list = []\n",
    "        for cand_idx, cand in candidate_objs:\n",
    "            iou_calcs = []\n",
    "\n",
    "            for next_seq_obj_idx, next_seq_obj in objs_to_concetenate:\n",
    "                a = convert_coco_poly_to_mask([cand[\"segmentations\"][i]], 1080, 1080)[0]\n",
    "                b = convert_coco_poly_to_mask([next_seq_obj[\"segmentations\"][i+1]], 1080, 1080)[0]\n",
    "                iou_calc = calculate_IoU(a, b)\n",
    "                iou_calcs.append(iou_calc)\n",
    "\n",
    "            if max(iou_calcs) > threshold:\n",
    "                counter += 1\n",
    "                max_index = np.argmax(iou_calcs)\n",
    "\n",
    "                cand[\"segmentations\"][i+1:i+11] = copy.deepcopy(objs_to_concetenate[max_index][1][\"segmentations\"][i+1:i+11])\n",
    "                video_objects_dict[cand_idx][\"segmentations\"] = copy.deepcopy(cand[\"segmentations\"])\n",
    "                keys_to_remove_list.append(objs_to_concetenate[max_index][0])\n",
    "    #             print(f\"cand_idx:{cand_idx} concetanated with next_seq_obj_idx: {i+1+max_index}, with iou: {max(iou_calcs)}\")\n",
    "\n",
    "            else:\n",
    "                max_index = np.argmax(iou_calcs)\n",
    "    #             print(f\"cand_idx:{cand_idx} CANNOT BE next_seq_obj_idx: {i+1+max_index}, max iou: {max(iou_calcs)}\")\n",
    "\n",
    "        keys_to_remove_list = list(set(keys_to_remove_list))\n",
    "        for key in keys_to_remove_list:\n",
    "            video_objects_dict.pop(key)\n",
    "\n",
    "    last_preds_list.append(copy.deepcopy(video_objects_dict))\n",
    "    print(f\"{ann_idx} done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8522780-8572-4e4a-9838-d59bb878c864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7a55fdac-b26e-41cf-a984-18b5a976b578",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [list(vid.values()) for vid in last_preds_list]\n",
    "\n",
    "import itertools\n",
    "all_preds = list(itertools.chain.from_iterable(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "791d0932-e43c-40d5-bd0b-5154cb9f3743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('evaluation/predictions_model_perceptual_gan_v2_003_last_version.json', 'w') as f:\n",
    "    json.dump(all_preds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54ba5e62-c9e7-4154-add6-a9adbd130b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1201\n",
      "1187\n",
      "1279\n",
      "1614\n"
     ]
    }
   ],
   "source": [
    "for i in last_preds_list:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89c62c75-2fe5-4281-b4f1-8399decc4b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1356\n",
      "832\n",
      "622\n",
      "405\n"
     ]
    }
   ],
   "source": [
    "video28_objects = [p for p in preds if p[\"video_id\"] == 28]\n",
    "# video28_objects_dict = {i:obj for i, obj in enumerate(video28_objects)}\n",
    "print(len(video28_objects))\n",
    "\n",
    "video28_objects = [p for p in preds if p[\"video_id\"] == 33]\n",
    "# video28_objects_dict = {i:obj for i, obj in enumerate(video28_objects)}\n",
    "print(len(video28_objects))\n",
    "\n",
    "video28_objects = [p for p in preds if p[\"video_id\"] == 42]\n",
    "# video28_objects_dict = {i:obj for i, obj in enumerate(video28_objects)}\n",
    "print(len(video28_objects))\n",
    "\n",
    "video28_objects = [p for p in preds if p[\"video_id\"] == 59]\n",
    "# video28_objects_dict = {i:obj for i, obj in enumerate(video28_objects)}\n",
    "print(len(video28_objects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2e6d96-fef5-4afd-bad2-7551e47d3c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab4f500-e812-49da-a935-fddb1c8b73a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [list(vid.values()) for vid in last_preds_list]\n",
    "\n",
    "import itertools\n",
    "all_preds = list(itertools.chain.from_iterable(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "877d9a68-fe7f-40ab-8afc-704140959120",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-64-bf5236dd0e9a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-64-bf5236dd0e9a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    preds_list = [vid for vid in last_preds_list obj for obj in list(vid.values())]\u001b[0m\n\u001b[0m                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# preds_list = [vid for vid in last_preds_list obj for obj in list(vid.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7704d807-9476-461a-a4d1-c0f3984b31e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c3b4e80-1d82-4cd0-bdfd-8b67b32fad3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1425"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video28_objects = [p for p in preds if p[\"video_id\"] == 28]\n",
    "# video28_objects_dict = {i:obj for i, obj in enumerate(video28_objects)}\n",
    "len(video28_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b113983-4061-484f-a4c5-5930bf523279",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_data_path = \"evaluation/gt_data_eval.json\"\n",
    "with open(gt_data_path) as fp:\n",
    "    gt_data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6db7f1b-6782-406c-a2cf-34b86ca6bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_data_33 = [ann for ann in gt_data[\"annotations\"] if ann[\"video_id\"] == 59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8830d544-3190-4e27-beff-377b2ce1c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gt_data_33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba25cdc0-62c6-45da-8616-9e750858a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gt_data[\"annotations\"][0][\"segmentations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f58b1c-7433-4455-b8d9-c290b1cded59",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_data[\"annotations\"][0][\"video_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bc489b-2ebd-4cb8-91cb-6098506db43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_indices = [28, 33, 42, 59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b717be3b-1455-44af-a61c-930aaf8b3786",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in last_preds_list:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4577fe-abd0-432d-986a-8b7dcf5ba0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(last_preds_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b32604-3c79-4e4a-9326-5b33548c444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in annotation_indices:\n",
    "    print(len([p for p in preds if p[\"video_id\"] == i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e289535-90e7-450b-9df8-0e5a94945608",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_preds_list[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdd6953-eb6e-4f4e-ab18-05b923538620",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predictions_model_gradient_2.json') as f:\n",
    "    preds = json.load(f)\n",
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba607d57-7915-49a2-9b4e-90b2eda71177",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predictions_toy.json') as f:\n",
    "    preds = json.load(f)\n",
    "    \n",
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02afb9e7-f2e2-4fc8-bdf9-04154752f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0][\"segmentations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f8d8f-b147-489f-8f6f-cf0e88f63518",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a18a1253-7eb6-48dc-b0b7-feed8686bf05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1958"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "abec4e37-b6f0-4168-886a-c353bf195999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3341"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2847bf60-2c0d-4a31-88e3-b5b7d0b5bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('evaluation/all_preds.json', 'w') as f:\n",
    "    json.dump(all_preds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85403b82-9e44-428b-8918-d3dbe46a0d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a1550b-06f2-4c08-8a92-17016d3ca3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_data_path = \"evaluation/gt_data_eval.json\"\n",
    "with open(gt_data_path) as fp:\n",
    "    example_data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4355f9af-6f1d-49ce-9652-f4c9a5095807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "42422f62-a73a-4424-97ea-af42b9d343b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_data_path = \"evaluation/gt_data_eval.json\"\n",
    "with open(gt_data_path) as fp:\n",
    "    gt_data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086b0348-cb29-47d1-87d1-708fe8cb496c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde537ed-a1a8-43a0-8dbe-d632a192a6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ea6e87-55f3-4bee-88b9-4dd7913f581e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c19ba4-bab3-4c8a-93a6-dee323968c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5ed49f-b351-458f-9bc3-0a6f5773344b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
